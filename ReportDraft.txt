Intro 

This report outlines the classification and cluster analysis undertaken as part of Data Mining CW1.


1. Classification

A bit about the dataset ********************** 

The dataset used in this section can be found at ... 

1.1
The information extracted from this dataset, in relation to missing values, are shown in the following table:

*** table ***

Given roughly 10% of the values in the dataset are missing, this presented a suitable opportunity to assess the impact 
that missing elements can have on data manipulation. The accompanying code must account for unexpected missing values
where necessary and convert them to usable data types, as will be shown in the following sections.


1.2

To train the classifiers used in the report, the missing data-points must be converted to usable data-types. The NaN value
that represents the missing data-points in the dataset is a floating point. To obtain the unique discrete values for each attribute, 
the data must be converted to categorical labels. It is not possible to convert floating point types to labels using the Scikit-Learn LabelEncoder,
so the NaN values must be replaced with a string (or int type). In this case a placeholder string 'missing' was used.

Using the label encoder, each of the values contained in the dataset were converted to a discrete numerical integer value. Each integer 
represents an attribute value for its respective column. It is important to note these integers represent only values containted within the 
dataset, and not other possible values that could occur despite not being present in the dataset. Numerical attributes
within the dataset would also be converted to discrete values, so this method should be avoided with continuous data types to avoid 
encoding problems when adding new data.

The discrete values are shown in the following table:

***Table***

1.3

Ignoring any instance with missing values, that is to say any row containing NaN or 'missing' values, a decision-tree classifier was trained
and its error rate computed. To do this, the NaN values were dropped, and the dataset encoded into discrete values. 
To train a classifier it is necessary to split the data into a set for training, and a set for testing. This is so the classifier's 
performance can be measured on data it has not yet seen. It will be biased to perform well on data it was trained on, so a separate 
test set is used for performance evaluation. 
The encoded dataset, except rows containing missing values, was therefore split in to train and test sets. The classifier was trained
on the train set, and the error rate computed on the test set.

The formula for calculating the error rate was as follows:

**** formula ***

The error rate was computed as 0.169

Due to randomness in the train_test_split function, this error rate will change slightly with each run of the test, depending on
how the data is split. 



1.4

Given the abundance of missing values in the dataset, there are multiple approaches to handling the training of the classifier. In this case
two datasets were created from a subset of the original dataset.

To create the subset, D', first every instance containing at leaset one missing value was extracted from the dataset. Next, an equal number of instances containing no
missing values were extracted. These two extracted datasets were combined and shuffled to avoid training bias. 

The first dataset from the subset, D'1, was created by simply replacing every NaN value in D' with a string; 'missing'.

The second dataset from the subset, D'2, was created by replacing the NaN values in D' with modal value for the respective attribute.

Two decision trees were trained on these separate datasets. Then, using instances from D (the original dataset) for testing which contained no missing values, 
the error rate was calculated on unseen data. The same test instances used for testing the classifier from 1.3 were used, which contained
no missing values. This would allow for more direct comparison between each of the classifiers.

The error rates for the classifiers were as follows:

Tree trained on D'1: 0.172
Tree trained on D'2: 0.187

Once again these error values will change with each run of the code, though it should be noted the classifier trained on D'1 consistently 
scored better than the one trained on D'2.

Both of these classifiers performed consistently worse than the classifier trained on the dataset with instances missing values 
removed (classifier from 1.3). This gives rise to several questions.

It could be that the two missing-value-handling methods used in this section have a negative effect on the performance of classifiers
on unseen data, i.e., manipulating the data in this way may hinder the accuracy of the models.

Given the classifiers were trained on data where 50% of instances had at least one missing value, it is possible there was bias in the 
training, as none of the testing examples contained any missing data.